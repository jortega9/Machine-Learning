{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 9: Conjuntos de árboles con XGBoost\n",
    "\n",
    "Grupo 5: Jorge Ortega y Daniela Vidal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE=83"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos\n",
    "\n",
    "En este notebook vamos a usar el conjunto de datos sobre flores del Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Cargamos el dataset del iris\n",
    "iris = load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=iris['data'], columns=iris['feature_names']) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <td>150.0</td>\n",
       "      <td>5.843333</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.80</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <td>150.0</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal length (cm)</th>\n",
       "      <td>150.0</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.35</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>petal width (cm)</th>\n",
       "      <td>150.0</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count      mean       std  min  25%   50%  75%  max\n",
       "sepal length (cm)  150.0  5.843333  0.828066  4.3  5.1  5.80  6.4  7.9\n",
       "sepal width (cm)   150.0  3.057333  0.435866  2.0  2.8  3.00  3.3  4.4\n",
       "petal length (cm)  150.0  3.758000  1.765298  1.0  1.6  4.35  5.1  6.9\n",
       "petal width (cm)   150.0  1.199333  0.762238  0.1  0.3  1.30  1.8  2.5"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el conjunto de datos en entrenamiento, test y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X, y_train, y = train_test_split(iris['data'], iris['target'], test_size=0.4, random_state=RANDOM_STATE)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X, y, test_size=0.5, random_state=RANDOM_STATE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamos el árbol con XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a construir un árbol de decisión usando los parámetros por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos el arbol sin estudiar los parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = XGBClassifier(objective='binary:logistic', n_estimators=10, seed=RANDOM_STATE)\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (np.sum(y_pred == y_test) / y_test.shape[0]) * 100\n",
    "print(\"Accuracy: %.2f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 90.00%\n"
     ]
    }
   ],
   "source": [
    "acurracy_score = model.score(X_test, y_test)\n",
    "print(\"Accuracy score: %.2f%%\" % (acurracy_score * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy: 96.67%\n"
     ]
    }
   ],
   "source": [
    "val_accuracy = model.score(X_val, y_val)\n",
    "print(\"Val accuracy: %.2f%%\" % (val_accuracy * 100.0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros más importantes son:\n",
    "\n",
    "objective: en el que indicamos que vamos a hacer un problema de clasificación binaria.\n",
    "\n",
    "n_estimators: el número de árboles que vamos a usar.\n",
    "\n",
    "max_depth: la profundidad máxima de cada árbol.\n",
    "\n",
    "learning_rate: la tasa de aprendizaje.\n",
    "\n",
    "Veamos cuales son los mejores parámetros para este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 50, 100, 200, 300]\n",
    "max_depths = [2, 3, 4, 7, 10]\n",
    "learning_rates = [0.001, 0.01, 0.1, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 96.67% Test accuracy: 86.67% n_estimators: 10 max_depth: 2 learning_rate: 0.001\n",
      "Train accuracy: 96.67% Test accuracy: 86.67% n_estimators: 10 max_depth: 2 learning_rate: 0.01\n",
      "Train accuracy: 98.89% Test accuracy: 90.00% n_estimators: 10 max_depth: 2 learning_rate: 0.1\n",
      "Train accuracy: 98.89% Test accuracy: 90.00% n_estimators: 10 max_depth: 2 learning_rate: 0.2\n",
      "Train accuracy: 98.89% Test accuracy: 90.00% n_estimators: 10 max_depth: 2 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 10 max_depth: 3 learning_rate: 0.001\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 10 max_depth: 3 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 10 max_depth: 3 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 10 max_depth: 3 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 10 max_depth: 3 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 10 max_depth: 4 learning_rate: 0.001\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 10 max_depth: 4 learning_rate: 0.01\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 10 max_depth: 4 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 10 max_depth: 4 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 10 max_depth: 4 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 10 max_depth: 7 learning_rate: 0.001\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 10 max_depth: 7 learning_rate: 0.01\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 10 max_depth: 7 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 10 max_depth: 7 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 10 max_depth: 7 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 10 max_depth: 10 learning_rate: 0.001\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 10 max_depth: 10 learning_rate: 0.01\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 10 max_depth: 10 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 10 max_depth: 10 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 10 max_depth: 10 learning_rate: 0.3\n",
      "Train accuracy: 96.67% Test accuracy: 86.67% n_estimators: 50 max_depth: 2 learning_rate: 0.001\n",
      "Train accuracy: 96.67% Test accuracy: 86.67% n_estimators: 50 max_depth: 2 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 2 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 2 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 2 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 50 max_depth: 3 learning_rate: 0.001\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 50 max_depth: 3 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 3 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 3 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 3 learning_rate: 0.3\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 50 max_depth: 4 learning_rate: 0.001\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 50 max_depth: 4 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 4 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 4 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 4 learning_rate: 0.3\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 50 max_depth: 7 learning_rate: 0.001\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 50 max_depth: 7 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 7 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 7 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 7 learning_rate: 0.3\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 50 max_depth: 10 learning_rate: 0.001\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 50 max_depth: 10 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 10 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 10 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 50 max_depth: 10 learning_rate: 0.3\n",
      "Train accuracy: 96.67% Test accuracy: 86.67% n_estimators: 100 max_depth: 2 learning_rate: 0.001\n",
      "Train accuracy: 98.89% Test accuracy: 90.00% n_estimators: 100 max_depth: 2 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 2 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 2 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 2 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 100 max_depth: 3 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 3 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 3 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 3 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 3 learning_rate: 0.3\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 100 max_depth: 4 learning_rate: 0.001\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 100 max_depth: 4 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 4 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 4 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 4 learning_rate: 0.3\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 100 max_depth: 7 learning_rate: 0.001\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 100 max_depth: 7 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 7 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 7 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 7 learning_rate: 0.3\n",
      "Train accuracy: 97.78% Test accuracy: 86.67% n_estimators: 100 max_depth: 10 learning_rate: 0.001\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 100 max_depth: 10 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 10 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 10 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 100 max_depth: 10 learning_rate: 0.3\n",
      "Train accuracy: 96.67% Test accuracy: 86.67% n_estimators: 200 max_depth: 2 learning_rate: 0.001\n",
      "Train accuracy: 98.89% Test accuracy: 90.00% n_estimators: 200 max_depth: 2 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 2 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 2 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 2 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 200 max_depth: 3 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 3 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 3 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 3 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 3 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 200 max_depth: 4 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 4 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 4 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 4 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 4 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 200 max_depth: 7 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 7 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 7 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 7 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 7 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 200 max_depth: 10 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 10 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 10 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 10 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 200 max_depth: 10 learning_rate: 0.3\n",
      "Train accuracy: 96.67% Test accuracy: 86.67% n_estimators: 300 max_depth: 2 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 2 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 2 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 2 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 2 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 300 max_depth: 3 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 3 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 3 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 3 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 3 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 300 max_depth: 4 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 4 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 4 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 4 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 4 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 300 max_depth: 7 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 7 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 7 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 7 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 7 learning_rate: 0.3\n",
      "Train accuracy: 98.89% Test accuracy: 86.67% n_estimators: 300 max_depth: 10 learning_rate: 0.001\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 10 learning_rate: 0.01\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 10 learning_rate: 0.1\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 10 learning_rate: 0.2\n",
      "Train accuracy: 100.00% Test accuracy: 90.00% n_estimators: 300 max_depth: 10 learning_rate: 0.3\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(objective='binary:logistic', seed=RANDOM_STATE)\n",
    "\n",
    "for ne in n_estimators:\n",
    "    for md in max_depths:\n",
    "        for lr in learning_rates:\n",
    "            model.set_params(n_estimators=ne, max_depth=md, learning_rate=lr)\n",
    "            model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "            train_accuracy = model.score(X_train, y_train) *100\n",
    "            test_accuracy = model.score(X_test, y_test) *100\n",
    "            \n",
    "            print(\"Train accuracy: %.2f%%\" % train_accuracy, \"Test accuracy: %.2f%%\" % test_accuracy,\"n_estimators:\", ne, \"max_depth:\", md, \"learning_rate:\", lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la vista de los resultados cogeremos los siguientes parámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ESTIMATOR = 200\n",
    "MAX_DEPTH = 2\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el árbol con los nuevos parámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 98.89% Test accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(objective='binary:logistic', n_estimators=N_ESTIMATOR, max_depth=MAX_DEPTH, learning_rate=LEARNING_RATE, seed=RANDOM_STATE)\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "train_accuracy = model.score(X_train, y_train) *100\n",
    "test_accuracy = model.score(X_test, y_test) *100\n",
    "\n",
    "print(\"Train accuracy: %.2f%%\" % train_accuracy, \"Test accuracy: %.2f%%\" % test_accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos obtenido una precisión del 98% en el conjunto de datos de entrenamiento y un 90% en el conjunto de datos de test. Lo cual nos muestra una alta tasa de acierto sin obtener sobreaprendizaje en el conjunto de datos de entrenamiento ya que se generaliza de manera adecuada para nuevos datos.\n",
    "\n",
    "Hemos visto que la profundidad máxima del árbol es el parametro mas importante, ya que si es muy grande se produce sobreaprendizaje y si es muy pequeña no se generaliza bien.\n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "Hemos visto que el XGBoost es un buen algoritmo para la construcción de árboles de decisión, ya que permite obtener una tasa de acierto muy alta sin sobreaprendizaje. Además, nos obtenemos los parámetros más importantes para el problema que de manera sencilla. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
